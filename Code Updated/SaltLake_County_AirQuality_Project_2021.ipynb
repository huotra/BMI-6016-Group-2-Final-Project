{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c60c62b-ff32-4d1a-a29e-eaf37411d4a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19632894-b60c-43a0-a7f7-107179e65312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time_stamp  pm2.5_atm\n",
      "327  2021-01-01    17.1790\n",
      "328  2021-01-02     6.8440\n",
      "329  2021-01-03     5.8115\n",
      "330  2021-01-04     8.6965\n",
      "331  2021-01-05     2.7620\n",
      "..          ...        ...\n",
      "587  2021-12-27     0.1515\n",
      "588  2021-12-28     0.6515\n",
      "589  2021-12-29    12.6345\n",
      "590  2021-12-30     0.5495\n",
      "591  2021-12-31     2.1825\n",
      "\n",
      "[265 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "year_to_filter = 2021\n",
    "df_13311 = pd.read_csv(\"13311.csv\")\n",
    "\n",
    "df_13311['time_stamp'] = pd.to_datetime(df_13311['time_stamp'])\n",
    "\n",
    "# Keep only the date part in the 'time_stamp' column\n",
    "df_13311['time_stamp'] = df_13311['time_stamp'].dt.date\n",
    "\n",
    "# Filter the DataFrame based on the year value\n",
    "filtered_df_13311 = df_13311[df_13311['time_stamp'].astype(str).str[:4] == str(year_to_filter)]\n",
    "filtered_df_13311_2_5 = filtered_df_13311[['time_stamp', 'pm2.5_atm']]\n",
    "filtered_df_13311_10 = filtered_df_13311[['time_stamp', 'pm10.0_atm']]\n",
    "print(filtered_df_13311_2_5)\n",
    "# print(filtered_df_13311_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a6b395-c89f-4100-ae6e-0fed1a6072f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pm2.5 concentration: 8.04977358490566\n",
      "Average pm10 concentration: 9.048745283018867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "average_pm25_13311 = filtered_df_13311_2_5['pm2.5_atm'].mean()\n",
    "average_pm10_13311 = filtered_df_13311_10['pm10.0_atm'].mean()\n",
    "\n",
    "print(\"Average pm2.5 concentration:\", average_pm25_13311)\n",
    "\n",
    "print(\"Average pm10 concentration:\", average_pm10_13311)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25228a7-229b-4c00-9ea0-e09087ddb3c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time_stamp  pm2.5_atm\n",
      "0      8/1/2021        3.9\n",
      "1      8/3/2021       10.2\n",
      "2      8/4/2021       18.6\n",
      "3      8/5/2021       12.9\n",
      "4      8/6/2021       49.2\n",
      "..          ...        ...\n",
      "501  12/27/2021        0.8\n",
      "502  12/28/2021        1.8\n",
      "503  12/29/2021        8.3\n",
      "504  12/30/2021        1.1\n",
      "505  12/31/2021        1.8\n",
      "\n",
      "[506 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_EPA_2_5 = pd.read_csv(\"EPA PM2.5 SLC 2021.csv\")\n",
    "site_id_to_filter = 490352005\n",
    "df_490352005_2_5 = df_EPA_2_5[df_EPA_2_5['Site ID'] == site_id_to_filter]\n",
    "df_490352005_2_5 = df_490352005_2_5.rename(columns={'Date': 'time_stamp', 'Daily Mean PM2.5 Concentration': 'pm2.5_atm'})\n",
    "\n",
    "# Select only the renamed columns\n",
    "df_filter_490352005_2_5 = df_490352005_2_5[['time_stamp', 'pm2.5_atm']]\n",
    "\n",
    "print(df_filter_490352005_2_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f9173a4-2f08-4631-bf86-1448aa005b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [time_stamp, pm10.0_atm]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_EPA_10 = pd.read_csv(\"EPA PM10 SLC 2021.csv\")\n",
    "# unique_site_ids = df_EPA_10['Site ID'].unique()\n",
    "# print(\"Unique Site IDs:\", unique_site_ids)\n",
    "site_id_to_filter = 490352005\n",
    "df_490352005_10 = df_EPA_10[df_EPA_10['Site ID'] == site_id_to_filter]\n",
    "df_490352005_10 = df_490352005_10.rename(columns={'Date': 'time_stamp', 'Daily Mean PM10 Concentration': 'pm10.0_atm'})\n",
    "\n",
    "# Select only the renamed columns\n",
    "df_filter_490352005_10 = df_490352005_10[['time_stamp', 'pm10.0_atm']]\n",
    "\n",
    "print(df_filter_490352005_10)\n",
    "\n",
    "# Unique Site IDs: [490353006 490353013 490353015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abb5b1a7-794e-4f7f-8f23-b924b3ad9a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.159520103761349\n",
      "9.048745283018867\n"
     ]
    }
   ],
   "source": [
    "union_df_cve_2_5 = pd.concat([filtered_df_13311_2_5, df_filter_490352005_2_5])\n",
    "union_df_cve_2_5['location'] = 'Copperview Elementary'\n",
    "\n",
    "average_df_cve_2_5 = union_df_cve_2_5['pm2.5_atm'].mean()\n",
    "\n",
    "filtered_df_13311_10['location'] = 'Copperview Elementary'\n",
    "union_df_cve_10 = filtered_df_13311_10\n",
    "\n",
    "average_df_cve_10 =union_df_cve_10['pm10.0_atm'].mean()\n",
    "\n",
    "print(average_df_cve_2_5)\n",
    "print(average_df_cve_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa0f92-02bd-461f-81b2-4985e7e8d5d5",
   "metadata": {},
   "source": [
    "6662_Purple Air\n",
    "EPA - Site ID: 490353006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e44a762-d31f-4186-abe7-3d40a1590dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time_stamp  pm2.5_atm\n",
      "366  2021-01-01    29.9290\n",
      "367  2021-01-02    16.2015\n",
      "368  2021-01-03    12.8625\n",
      "369  2021-01-04    18.7040\n",
      "370  2021-01-05    10.3265\n",
      "..          ...        ...\n",
      "726  2021-12-27     0.2640\n",
      "727  2021-12-28     0.9170\n",
      "728  2021-12-29    10.6230\n",
      "729  2021-12-30     0.3105\n",
      "730  2021-12-31     2.6000\n",
      "\n",
      "[365 rows x 2 columns]\n",
      "     time_stamp  pm10.0_atm\n",
      "366  2021-01-01     34.2260\n",
      "367  2021-01-02     17.7210\n",
      "368  2021-01-03     13.8980\n",
      "369  2021-01-04     19.8665\n",
      "370  2021-01-05     11.1785\n",
      "..          ...         ...\n",
      "726  2021-12-27      0.3235\n",
      "727  2021-12-28      1.0455\n",
      "728  2021-12-29     11.1245\n",
      "729  2021-12-30      0.3515\n",
      "730  2021-12-31      2.7575\n",
      "\n",
      "[365 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "year_to_filter = 2021\n",
    "df_6622 = pd.read_csv(\"6622.csv\")\n",
    "\n",
    "df_6622['time_stamp'] = pd.to_datetime(df_6622['time_stamp'])\n",
    "\n",
    "# Keep only the date part in the 'time_stamp' column\n",
    "df_6622['time_stamp'] = df_6622['time_stamp'].dt.date\n",
    "\n",
    "# Filter the DataFrame based on the year value\n",
    "filtered_df_6622 = df_6622[df_6622['time_stamp'].astype(str).str[:4] == str(year_to_filter)]\n",
    "filtered_df_6622_2_5 = filtered_df_6622[['time_stamp', 'pm2.5_atm']]\n",
    "filtered_df_6622_10 = filtered_df_6622[['time_stamp', 'pm10.0_atm']]\n",
    "print(filtered_df_6622_2_5)\n",
    "print(filtered_df_6622_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e6fc35e-949c-4a95-8ff6-98535d170c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pm2.5 concentration: 9.279160273972604\n",
      "Average pm10 concentration: 10.418500000000002\n"
     ]
    }
   ],
   "source": [
    "average_pm25_6622 = filtered_df_6622_2_5['pm2.5_atm'].mean()\n",
    "average_pm10_6622 = filtered_df_6622_10['pm10.0_atm'].mean()\n",
    "\n",
    "print(\"Average pm2.5 concentration:\", average_pm25_6622)\n",
    "\n",
    "print(\"Average pm10 concentration:\", average_pm10_6622)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87505145-2fff-4cf5-bc85-ddcb2dd1a5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      time_stamp  pm2.5_atm\n",
      "506     1/1/2021       16.5\n",
      "507     1/2/2021       10.9\n",
      "508     1/3/2021       10.5\n",
      "509     1/4/2021       10.6\n",
      "510     1/5/2021        3.3\n",
      "...          ...        ...\n",
      "1579  12/27/2021        1.2\n",
      "1580  12/28/2021        1.3\n",
      "1581  12/29/2021        5.3\n",
      "1582  12/30/2021        0.9\n",
      "1583  12/31/2021        3.7\n",
      "\n",
      "[1078 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_EPA_2_5 = pd.read_csv(\"EPA PM2.5 SLC 2021.csv\")\n",
    "site_id_to_filter = 490353006\n",
    "df_490352006_2_5 = df_EPA_2_5[df_EPA_2_5['Site ID'] == site_id_to_filter]\n",
    "df_490352006_2_5 = df_490352006_2_5.rename(columns={'Date': 'time_stamp', 'Daily Mean PM2.5 Concentration': 'pm2.5_atm'})\n",
    "\n",
    "# Select only the renamed columns\n",
    "df_filter_490352006_2_5 = df_490352006_2_5[['time_stamp', 'pm2.5_atm']]\n",
    "\n",
    "print(df_filter_490352006_2_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cd8ce31-d67d-42d2-a674-709791c8c40d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time_stamp  pm10.0_atm\n",
      "0      1/1/2021          25\n",
      "1      1/2/2021          25\n",
      "2      1/3/2021          17\n",
      "3      1/4/2021          24\n",
      "4      1/5/2021          11\n",
      "..          ...         ...\n",
      "347  12/27/2021          10\n",
      "348  12/28/2021           6\n",
      "349  12/29/2021          10\n",
      "350  12/30/2021           5\n",
      "351  12/31/2021           6\n",
      "\n",
      "[352 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_EPA_10 = pd.read_csv(\"EPA PM10 SLC 2021.csv\")\n",
    "# unique_site_ids = df_EPA_10['Site ID'].unique()\n",
    "# print(\"Unique Site IDs:\", unique_site_ids)\n",
    "site_id_to_filter =490353006\n",
    "df_490352006_10 = df_EPA_10[df_EPA_10['Site ID'] == site_id_to_filter]\n",
    "df_490352006_10 = df_490352006_10.rename(columns={'Date': 'time_stamp', 'Daily Mean PM10 Concentration': 'pm10.0_atm'})\n",
    "\n",
    "# Select only the renamed columns\n",
    "df_filter_490352006_10 = df_490352006_10[['time_stamp', 'pm10.0_atm']]\n",
    "\n",
    "print(df_filter_490352006_10)\n",
    "\n",
    "# Unique Site IDs: [490353006 490353013 490353015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bd75d6c-a076-434e-9cb2-c526d40f0b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.788214483714485\n",
      "16.312067642956766\n"
     ]
    }
   ],
   "source": [
    "union_df_ka_2_5 = pd.concat([filtered_df_6622_2_5, df_filter_490352006_2_5])\n",
    "union_df_ka_2_5['location'] = 'Hawthorne'\n",
    "\n",
    "average_df_ka_2_5 = union_df_ka_2_5['pm2.5_atm'].mean()\n",
    "\n",
    "union_df_ka_10 = pd.concat([filtered_df_6622_10, df_filter_490352006_10])\n",
    "\n",
    "union_df_ka_10['location'] = 'Hawthorne'\n",
    "average_df_ka_10 =union_df_ka_10['pm10.0_atm'].mean()\n",
    "\n",
    "print(average_df_ka_2_5)\n",
    "print(average_df_ka_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f342563-847b-4aa7-a832-acd9b834e78c",
   "metadata": {},
   "source": [
    "3) ROSE PARK\n",
    "EPA = 40.78422,-111.931 (Site ID: 490353010) \n",
    "PA = 90285\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8202c08-e611-4480-ba36-de0c469159de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time_stamp  pm2.5_atm\n",
      "1    2021-01-06   199.3880\n",
      "2    2021-01-07     9.3450\n",
      "3    2021-04-03     4.7985\n",
      "4    2021-04-04     6.5985\n",
      "5    2021-04-05     4.9310\n",
      "..          ...        ...\n",
      "269  2021-12-27     2.0435\n",
      "270  2021-12-28     2.3790\n",
      "271  2021-12-29    17.0695\n",
      "272  2021-12-30     2.4770\n",
      "273  2021-12-31     5.1795\n",
      "\n",
      "[273 rows x 2 columns]\n",
      "     time_stamp  pm10.0_atm\n",
      "1    2021-01-06    263.8280\n",
      "2    2021-01-07     10.6835\n",
      "3    2021-04-03      4.9775\n",
      "4    2021-04-04      7.0520\n",
      "5    2021-04-05      5.5295\n",
      "..          ...         ...\n",
      "269  2021-12-27      2.2670\n",
      "270  2021-12-28      2.6505\n",
      "271  2021-12-29     18.5675\n",
      "272  2021-12-30      2.6290\n",
      "273  2021-12-31      5.5440\n",
      "\n",
      "[273 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "year_to_filter = 2021\n",
    "df_90285 = pd.read_csv(\"90285.csv\")\n",
    "\n",
    "df_90285['time_stamp'] = pd.to_datetime(df_90285['time_stamp'])\n",
    "\n",
    "# Keep only the date part in the 'time_stamp' column\n",
    "df_90285['time_stamp'] = df_90285['time_stamp'].dt.date\n",
    "\n",
    "# Filter the DataFrame based on the year value\n",
    "filtered_df_90285 = df_90285[df_90285['time_stamp'].astype(str).str[:4] == str(year_to_filter)]\n",
    "filtered_df_90285_2_5 = filtered_df_90285[['time_stamp', 'pm2.5_atm']]\n",
    "filtered_df_90285_10 = filtered_df_90285[['time_stamp', 'pm10.0_atm']]\n",
    "print(filtered_df_90285_2_5)\n",
    "print(filtered_df_90285_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04bbb9c7-b523-4185-b21d-d320f06d9020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pm2.5 concentration: 15.43634065934066\n",
      "Average pm10 concentration: 17.85679304029304\n"
     ]
    }
   ],
   "source": [
    "average_pm25_90285 = filtered_df_90285_2_5['pm2.5_atm'].mean()\n",
    "average_pm10_90285 = filtered_df_90285_10['pm10.0_atm'].mean()\n",
    "\n",
    "print(\"Average pm2.5 concentration:\", average_pm25_90285)\n",
    "\n",
    "print(\"Average pm10 concentration:\", average_pm10_90285)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b836f0b7-e58f-4aac-a89f-79f38cad318e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      time_stamp  pm2.5_atm\n",
      "1584    1/1/2021       15.2\n",
      "1585    1/2/2021       10.5\n",
      "1586    1/3/2021       10.4\n",
      "1587    1/4/2021       11.6\n",
      "1588    1/5/2021        4.0\n",
      "...          ...        ...\n",
      "2655  12/27/2021        3.2\n",
      "2656  12/28/2021        1.7\n",
      "2657  12/29/2021        7.4\n",
      "2658  12/30/2021        0.8\n",
      "2659  12/31/2021        2.8\n",
      "\n",
      "[1076 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_EPA_2_5 = pd.read_csv(\"EPA PM2.5 SLC 2021.csv\")\n",
    "site_id_to_filter = 490353010\n",
    "df_490353010_2_5 = df_EPA_2_5[df_EPA_2_5['Site ID'] == site_id_to_filter]\n",
    "df_490353010_2_5 = df_490353010_2_5.rename(columns={'Date': 'time_stamp', 'Daily Mean PM2.5 Concentration': 'pm2.5_atm'})\n",
    "# Select only the renamed columns\n",
    "df_filter_490353010_2_5 = df_490353010_2_5[['time_stamp', 'pm2.5_atm']]\n",
    "# df_av = df_filter_490353010_2_5['pm2.5_atm'].mean()\n",
    "# print(df)\n",
    "print(df_filter_490353010_2_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09e6e06b-08f9-45d0-8288-49afee9df7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [time_stamp, pm10.0_atm]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_EPA_10 = pd.read_csv(\"EPA PM10 SLC 2021.csv\")\n",
    "# unique_site_ids = df_EPA_10['Site ID'].unique()\n",
    "# print(\"Unique Site IDs:\", unique_site_ids)\n",
    "site_id_to_filter =490353010\n",
    "df_490353010_10 = df_EPA_10[df_EPA_10['Site ID'] == site_id_to_filter]\n",
    "df_490353010_10 = df_490353010_10.rename(columns={'Date': 'time_stamp', 'Daily Mean PM10 Concentration': 'pm10.0_atm'})\n",
    "\n",
    "# Select only the renamed columns\n",
    "df_filter_490353010_10 = df_490353010_10[['time_stamp', 'pm10.0_atm']]\n",
    "\n",
    "print(df_filter_490353010_10)\n",
    "\n",
    "# Unique Site IDs: [490353006 490353013 490353015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89535b20-fb6d-4521-a2f6-0a8c3f0bc89b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.412246849518162\n",
      "17.85679304029304\n"
     ]
    }
   ],
   "source": [
    "union_df_rp_2_5 = pd.concat([filtered_df_90285_2_5, df_filter_490353010_2_5])\n",
    "union_df_rp_2_5['location'] = 'Rose Park'\n",
    "\n",
    "average_df_rp_2_5 = union_df_rp_2_5['pm2.5_atm'].mean()\n",
    "\n",
    "union_df_rp_10 = pd.concat([filtered_df_90285_10, df_filter_490353010_10])\n",
    "\n",
    "union_df_rp_10['location'] = 'Rose Park'\n",
    "average_df_rp_10 =filtered_df_90285_10['pm10.0_atm'].mean()\n",
    "\n",
    "print(average_df_rp_2_5)\n",
    "print(average_df_rp_10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dd1942-26ae-4f77-a51e-b97a8a97e316",
   "metadata": {},
   "source": [
    "4) Jordan Meadows\n",
    "EPA = 40.777145,-111.945849 (Site ID: 490353015) \n",
    "PA = 20897\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ce2bf75-806f-4210-b3b2-83719b473473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time_stamp  pm2.5_atm\n",
      "366  2021-01-01    42.6845\n",
      "367  2021-01-02    18.7690\n",
      "368  2021-01-03    24.9950\n",
      "369  2021-01-04    21.9125\n",
      "370  2021-01-05    15.6930\n",
      "..          ...        ...\n",
      "726  2021-12-27     0.5865\n",
      "727  2021-12-28     1.2055\n",
      "728  2021-12-29    16.0120\n",
      "729  2021-12-30     0.8510\n",
      "730  2021-12-31     3.1860\n",
      "\n",
      "[365 rows x 2 columns]\n",
      "     time_stamp  pm10.0_atm\n",
      "366  2021-01-01     56.4305\n",
      "367  2021-01-02     23.2975\n",
      "368  2021-01-03     31.6510\n",
      "369  2021-01-04     25.4540\n",
      "370  2021-01-05     19.1365\n",
      "..          ...         ...\n",
      "726  2021-12-27      0.9670\n",
      "727  2021-12-28      1.7850\n",
      "728  2021-12-29     18.8920\n",
      "729  2021-12-30      1.1685\n",
      "730  2021-12-31      3.8325\n",
      "\n",
      "[365 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "year_to_filter = 2021\n",
    "df_20897 = pd.read_csv(\"20897.csv\")\n",
    "\n",
    "df_20897['time_stamp'] = pd.to_datetime(df_20897['time_stamp'])\n",
    "\n",
    "# Keep only the date part in the 'time_stamp' column\n",
    "df_20897['time_stamp'] = df_20897['time_stamp'].dt.date\n",
    "\n",
    "# Filter the DataFrame based on the year value\n",
    "filtered_df_20897 = df_20897[df_20897['time_stamp'].astype(str).str[:4] == str(year_to_filter)]\n",
    "filtered_df_20897_2_5 = filtered_df_20897[['time_stamp', 'pm2.5_atm']]\n",
    "filtered_df_20897_10 = filtered_df_20897[['time_stamp', 'pm10.0_atm']]\n",
    "print(filtered_df_20897_2_5)\n",
    "print(filtered_df_20897_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "030f2943-2d07-46fd-94f2-e58a1682e894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pm2.5 concentration: 12.671801369863012\n",
      "Average pm10 concentration: 15.378767123287671\n"
     ]
    }
   ],
   "source": [
    "average_pm25_20897 = filtered_df_20897_2_5['pm2.5_atm'].mean()\n",
    "average_pm10_20897 = filtered_df_20897_10['pm10.0_atm'].mean()\n",
    "\n",
    "print(\"Average pm2.5 concentration:\", average_pm25_20897)\n",
    "\n",
    "print(\"Average pm10 concentration:\", average_pm10_20897)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cf9cc1d-1af3-4957-bce9-e691c9f23b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      time_stamp  pm2.5_atm\n",
      "3442    1/1/2021       15.9\n",
      "3443    1/2/2021       11.4\n",
      "3444    1/3/2021       12.2\n",
      "3445    1/4/2021       11.4\n",
      "3446    1/5/2021        4.6\n",
      "...          ...        ...\n",
      "4126  12/27/2021        0.9\n",
      "4127  12/28/2021        0.6\n",
      "4128  12/29/2021        6.3\n",
      "4129  12/30/2021        0.8\n",
      "4130  12/31/2021        1.4\n",
      "\n",
      "[689 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_EPA_2_5 = pd.read_csv(\"EPA PM2.5 SLC 2021.csv\")\n",
    "site_id_to_filter = 490353015\n",
    "df_490353015_2_5 = df_EPA_2_5[df_EPA_2_5['Site ID'] == site_id_to_filter]\n",
    "df_490353015_2_5 = df_490353015_2_5.rename(columns={'Date': 'time_stamp', 'Daily Mean PM2.5 Concentration': 'pm2.5_atm'})\n",
    "\n",
    "# Select only the renamed columns\n",
    "df_filter_490353015_2_5 = df_490353015_2_5[['time_stamp', 'pm2.5_atm']]\n",
    "\n",
    "print(df_filter_490353015_2_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0428643-cc28-49d1-b243-1879bc98727e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      time_stamp  pm10.0_atm\n",
      "713     1/1/2021          20\n",
      "714     1/2/2021          21\n",
      "715     1/3/2021          21\n",
      "716     1/4/2021          21\n",
      "717     1/5/2021          16\n",
      "...          ...         ...\n",
      "1070  12/27/2021          12\n",
      "1071  12/28/2021           6\n",
      "1072  12/29/2021          15\n",
      "1073  12/30/2021           7\n",
      "1074  12/31/2021           6\n",
      "\n",
      "[362 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_EPA_10 = pd.read_csv(\"EPA PM10 SLC 2021.csv\")\n",
    "# unique_site_ids = df_EPA_10['Site ID'].unique()\n",
    "# print(\"Unique Site IDs:\", unique_site_ids)\n",
    "site_id_to_filter =490353015\n",
    "df_490353015_10 = df_EPA_10[df_EPA_10['Site ID'] == site_id_to_filter]\n",
    "df_490353015_10 = df_490353015_10.rename(columns={'Date': 'time_stamp', 'Daily Mean PM10 Concentration': 'pm10.0_atm'})\n",
    "\n",
    "# Select only the renamed columns\n",
    "df_filter_490353015_10 = df_490353015_10[['time_stamp', 'pm10.0_atm']]\n",
    "\n",
    "print(df_filter_490353015_10)\n",
    "\n",
    "# Unique Site IDs: [490353006 490353013 490353015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71005b82-fa5f-4bdb-923a-555a1db2881d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.483403700189752\n",
      "21.212173314993123\n"
     ]
    }
   ],
   "source": [
    "union_df_jm_2_5 = pd.concat([filtered_df_20897_2_5, df_filter_490353015_2_5])\n",
    "union_df_jm_2_5['location'] = 'Utah Technical Center'\n",
    "\n",
    "average_df_jm_2_5 = union_df_jm_2_5['pm2.5_atm'].mean()\n",
    "\n",
    "union_df_jm_10 = pd.concat([filtered_df_20897_10, df_filter_490353015_10])\n",
    "\n",
    "union_df_jm_10['location'] = 'Utah Technical Center'\n",
    "average_df_jm_10 =union_df_jm_10['pm10.0_atm'].mean()\n",
    "\n",
    "print(average_df_jm_2_5)\n",
    "print(average_df_jm_10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb9fff6-94aa-4e53-bab6-807c4033b7d6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "5) Near Road\n",
    "EPA = 40.6629611,-111.9018514  (Site ID: 490354002)\n",
    "PA = 18169\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19c83ad3-8725-49a1-83fd-bd2d31466fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time_stamp  pm2.5_atm\n",
      "360  2021-01-01    43.7130\n",
      "361  2021-01-02    20.4895\n",
      "362  2021-01-03    19.7210\n",
      "363  2021-01-04    18.1615\n",
      "364  2021-01-05    12.1990\n",
      "..          ...        ...\n",
      "719  2021-12-27     0.1410\n",
      "720  2021-12-28     1.4030\n",
      "721  2021-12-29    14.7360\n",
      "722  2021-12-30     0.4815\n",
      "723  2021-12-31     2.5290\n",
      "\n",
      "[364 rows x 2 columns]\n",
      "     time_stamp  pm10.0_atm\n",
      "360  2021-01-01     58.4710\n",
      "361  2021-01-02     25.8540\n",
      "362  2021-01-03     24.5855\n",
      "363  2021-01-04     21.0750\n",
      "364  2021-01-05     15.0010\n",
      "..          ...         ...\n",
      "719  2021-12-27      0.3365\n",
      "720  2021-12-28      1.8810\n",
      "721  2021-12-29     16.7220\n",
      "722  2021-12-30      0.6815\n",
      "723  2021-12-31      3.0685\n",
      "\n",
      "[364 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "year_to_filter = 2021\n",
    "df_18169 = pd.read_csv(\"18169.csv\")\n",
    "\n",
    "df_18169['time_stamp'] = pd.to_datetime(df_18169['time_stamp'])\n",
    "\n",
    "# Keep only the date part in the 'time_stamp' column\n",
    "df_18169['time_stamp'] = df_18169['time_stamp'].dt.date\n",
    "\n",
    "# Filter the DataFrame based on the year value\n",
    "filtered_df_18169 = df_18169[df_18169['time_stamp'].astype(str).str[:4] == str(year_to_filter)]\n",
    "filtered_df_18169_2_5 = filtered_df_18169[['time_stamp', 'pm2.5_atm']]\n",
    "filtered_df_18169_10 = filtered_df_18169[['time_stamp', 'pm10.0_atm']]\n",
    "print(filtered_df_18169_2_5)\n",
    "print(filtered_df_18169_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d3aad1b-a7f3-49bb-9be8-ec3c7b7e59d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pm2.5 concentration: 11.613532967032967\n",
      "Average pm10 concentration: 13.969373626373626\n"
     ]
    }
   ],
   "source": [
    "average_pm25_18169 = filtered_df_18169_2_5['pm2.5_atm'].mean()\n",
    "average_pm10_18169 = filtered_df_18169_10['pm10.0_atm'].mean()\n",
    "\n",
    "print(\"Average pm2.5 concentration:\", average_pm25_18169)\n",
    "\n",
    "print(\"Average pm10 concentration:\", average_pm10_18169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b1a8fb0-d17c-4469-a6d9-015aecba2aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      time_stamp  pm2.5_atm\n",
      "4406    1/1/2021       21.0\n",
      "4407    1/2/2021       10.5\n",
      "4408    1/3/2021       11.6\n",
      "4409    1/4/2021       12.6\n",
      "4410    1/5/2021        5.8\n",
      "...          ...        ...\n",
      "4919  12/27/2021        2.6\n",
      "4920  12/28/2021        3.7\n",
      "4921  12/29/2021        9.7\n",
      "4922  12/30/2021        2.6\n",
      "4923  12/31/2021        3.6\n",
      "\n",
      "[518 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_EPA_2_5 = pd.read_csv(\"EPA PM2.5 SLC 2021.csv\")\n",
    "site_id_to_filter = 490354002\n",
    "df_490354002_2_5 = df_EPA_2_5[df_EPA_2_5['Site ID'] == site_id_to_filter]\n",
    "df_490354002_2_5 = df_490354002_2_5.rename(columns={'Date': 'time_stamp', 'Daily Mean PM2.5 Concentration': 'pm2.5_atm'})\n",
    "\n",
    "# Select only the renamed columns\n",
    "df_filter_490354002_2_5 = df_490354002_2_5[['time_stamp', 'pm2.5_atm']]\n",
    "\n",
    "print(df_filter_490354002_2_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39689e9b-8d07-470e-879c-9b9c13778a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [time_stamp, pm10.0_atm]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_EPA_10 = pd.read_csv(\"EPA PM10 SLC 2021.csv\")\n",
    "# unique_site_ids = df_EPA_10['Site ID'].unique()\n",
    "# print(\"Unique Site IDs:\", unique_site_ids)\n",
    "site_id_to_filter =490354002\n",
    "df_490354002_10 = df_EPA_10[df_EPA_10['Site ID'] == site_id_to_filter]\n",
    "df_490354002_10 = df_490354002_10.rename(columns={'Date': 'time_stamp', 'Daily Mean PM10 Concentration': 'pm10.0_atm'})\n",
    "\n",
    "# Select only the renamed columns\n",
    "df_filter_490354002_10 = df_490354002_10[['time_stamp', 'pm10.0_atm']]\n",
    "\n",
    "print(df_filter_490354002_10)\n",
    "\n",
    "# Unique Site IDs: [490353006 490353013 490353015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "390b1574-7ad1-424d-9090-6b02a4e6f534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.450596371882085\n",
      "13.969373626373626\n"
     ]
    }
   ],
   "source": [
    "union_df_nearroad_2_5 = pd.concat([filtered_df_18169_2_5, df_filter_490354002_2_5])\n",
    "union_df_nearroad_2_5['location'] = 'Hawthorne'\n",
    "\n",
    "average_df_nearroad_2_5 = union_df_nearroad_2_5['pm2.5_atm'].mean()\n",
    "\n",
    "union_df_nearroad_10 = pd.concat([filtered_df_18169_10, df_filter_490354002_10])\n",
    "\n",
    "union_df_nearroad_10['location'] = 'Near Road'\n",
    "average_df_nearroad_10 =union_df_nearroad_10['pm10.0_atm'].mean()\n",
    "\n",
    "print(average_df_nearroad_2_5)\n",
    "print(average_df_nearroad_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79a883e-1a72-4777-a4be-f25448c8a718",
   "metadata": {},
   "source": [
    "4) Jordan Meadows\n",
    "EPA = 40.777145,-111.945849 (Site ID: 490353015) \n",
    "PA = 20897\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550b2f4-dd79-4caf-aaa6-9e898b558179",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "Cities = ['Copperview Elementary', 'Hawthorne', 'Rose Park', 'Utah Technical Center', 'Near Road']\n",
    "pm2_5 = [average_df_cve_2_5, average_df_ka_2_5, average_df_rp_2_5, average_df_jm_2_5, average_df_nearroad_2_5]\n",
    "pm10 = [average_df_cve_10, average_df_ka_10, average_df_rp_10, average_df_jm_10, average_df_nearroad_10]\n",
    "\n",
    "# Width of each bar\n",
    "bar_width = 0.35\n",
    "\n",
    "# Index for each county\n",
    "x = range(len(Cities))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "bars1 = ax.bar(x, pm2_5, bar_width, label = 'PM2.5')\n",
    "bars2 = ax.bar([i + bar_width for i in x], pm10, bar_width, label = 'PM10.0')\n",
    "\n",
    "# Adding labels, title, and ticks\n",
    "ax.set_xlabel('Cities')\n",
    "ax.set_ylabel('Average PM Concentration')\n",
    "ax.set_title('Average PM2.5 and PM10.0 Concentrations by City (2021)')\n",
    "ax.set_xticks([i + bar_width/2 for i in x])\n",
    "ax.set_xticklabels(counties)\n",
    "ax.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9396a095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the data dictionary for PM2.5 and PM10 values by county\n",
    "average_concentrations_data_2023 = {\n",
    "    'Copperview Elementary': {'PM2.5': pm2_5[0], 'PM10': pm10[0]},\n",
    "    'Hawthorne': {'PM2.5': pm2_5[1], 'PM10': pm10[1]},\n",
    "    'Rose Park': {'PM2.5': pm2_5[2], 'PM10': pm10[2]},\n",
    "    'Utah Technical Center': {'PM2.5': pm2_5[3], 'PM10': pm10[3]},\n",
    "    'Near Road': {'PM2.5': pm2_5[4], 'PM10': pm10[4]}\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "pm_data_df = pd.DataFrame.from_dict(average_concentrations_data_2023, orient='index').reset_index()\n",
    "pm_data_df.rename(columns={'index': 'County'}, inplace=True)\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'pm_concentrations2023.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "pm_data_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"CSV file has been created at {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a57219-21db-4eb5-8a37-7e002ab6753a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Concatenate PM2.5 data into one DataFrame\n",
    "pm2_5df = pd.concat([union_df_cve_2_5, union_df_ka_2_5, union_df_rp_2_5, union_df_jm_2_5, union_df_nearroad_2_5])\n",
    "\n",
    "# Save PM2.5 data to CSV file with only 'time_stamp' and 'pm2.5' columns\n",
    "pm2_5df[['time_stamp', 'pm2.5_atm']].to_csv('pm25_data_2023.csv', index=False)\n",
    "\n",
    "print(\"File 'pm25_data.csv' has been created successfully.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679d119-17b4-4a76-b6c3-cbc0e8d64976",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Concatenate PM2.5 data into one DataFrame\n",
    "pm10df = pd.concat([union_df_cve_10, union_df_ka_10 , union_df_rp_10, union_df_jm_10, union_df_nearroad_10])\n",
    "\n",
    "# Save PM2.5 data to CSV file with only 'time_stamp' and 'pm2.5' columns\n",
    "pm10df[['time_stamp', 'pm10.0_atm']].to_csv('pm10_data_2023.csv', index=False)\n",
    "\n",
    "print(\"File 'pm10_data.csv' has been created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd833b3",
   "metadata": {},
   "source": [
    "Putting together all the PM concentration CSVs together in the cell below for combined plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6526008",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming each CSV file is named 'pm_concentrationsYYYY.csv', where YYYY is the year\n",
    "years = [2020, 2021, 2022, 2023]\n",
    "data = {}\n",
    "\n",
    "# Load data from each file\n",
    "for year in years:\n",
    "    df = pd.read_csv(f'pm_concentrations{year}.csv')\n",
    "    # The structure of CSV file is:\n",
    "    # City,PM2.5,PM10\n",
    "    # where PM2.5 and PM10 are columns containing the respective pollutant's concentration values for each city.\n",
    "    data[str(year)] = {row['County']: [row['PM2.5'], row['PM10']] for index, row in df.iterrows()}\n",
    "\n",
    "# Set up the figure and axes for two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 14))\n",
    "\n",
    "# Set the x-axis to the city names\n",
    "x = list(data['2020'].keys())  # Using 2020 as the basis; all files have the same city structure\n",
    "x_positions = np.arange(len(x))\n",
    "\n",
    "# Loop through each year and plot the data on respective subplots\n",
    "for year in data:\n",
    "    # PM2.5 data\n",
    "    y_pm2_5 = [data[year][city][0] for city in x]\n",
    "    # PM10 data\n",
    "    y_pm10 = [data[year][city][1] for city in x]\n",
    "\n",
    "    # Plot the PM2.5 data on the first subplot\n",
    "    ax1.plot(x_positions, y_pm2_5, marker='o', label=f'PM2.5 {year}')\n",
    "    # Plot the PM10 data on the second subplot\n",
    "    ax2.plot(x_positions, y_pm10, marker='x', linestyle='--', label=f'PM10 {year}')\n",
    "\n",
    "# Configure the first subplot\n",
    "ax1.set_xticks(x_positions)\n",
    "ax1.set_xticklabels(x, rotation=45)\n",
    "ax1.set_xlabel('Cities')\n",
    "ax1.set_ylabel('Average PM2.5 Concentration')\n",
    "ax1.set_title('Yearly Average PM2.5 Concentrations by City')\n",
    "ax1.legend()\n",
    "\n",
    "# Configure the second subplot\n",
    "ax2.set_xticks(x_positions)\n",
    "ax2.set_xticklabels(x, rotation=45)\n",
    "ax2.set_xlabel('Cities')\n",
    "ax2.set_ylabel('Average PM10 Concentration')\n",
    "ax2.set_title('Yearly Average PM10.0 Concentrations by City')\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44545408",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "years = [2020, 2021, 2022, 2023]\n",
    "data = {}\n",
    "\n",
    "# Load data from each file and calculate yearly averages\n",
    "yearly_averages = {}\n",
    "for year in years:\n",
    "    df = pd.read_csv(f'pm_concentrations{year}.csv')\n",
    "    # Compute the mean of PM2.5 and PM10 across all counties for this year\n",
    "    mean_pm2_5 = df['PM2.5'].mean()\n",
    "    mean_pm10 = df['PM10'].mean()\n",
    "    yearly_averages[year] = {'PM2.5': mean_pm2_5, 'PM10': mean_pm10}\n",
    "\n",
    "# Set up the figure\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Plotting data\n",
    "years = list(yearly_averages.keys())\n",
    "pm2_5_averages = [yearly_averages[year]['PM2.5'] for year in years]\n",
    "pm10_averages = [yearly_averages[year]['PM10'] for year in years]\n",
    "\n",
    "# X positions for the plot\n",
    "x_positions = np.arange(len(years))\n",
    "\n",
    "# Plot the averages\n",
    "ax.plot(x_positions, pm2_5_averages, marker='o', label='Average PM2.5', linestyle='-', color='blue')\n",
    "ax.plot(x_positions, pm10_averages, marker='x', label='Average PM10', linestyle='--', color='red')\n",
    "\n",
    "# Label the x-axis with year names\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(years)\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Average PM Concentration')\n",
    "ax.set_title('Yearly Combined Average PM2.5 and PM10 Concentrations')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae946169",
   "metadata": {},
   "source": [
    "# I was also testing a bunch of other ways we could visualize but these were cluttered so we decided to stick with the above 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996dbaa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "years = [2020, 2021, 2022, 2023]\n",
    "data = {}\n",
    "\n",
    "# Load data from each file and calculate yearly averages\n",
    "yearly_averages = {}\n",
    "all_data = {}\n",
    "\n",
    "for year in years:\n",
    "    df = pd.read_csv(f'pm_concentrations{year}.csv')\n",
    "    mean_pm2_5 = df['PM2.5'].mean()\n",
    "    mean_pm10 = df['PM10'].mean()\n",
    "    yearly_averages[year] = {'PM2.5': mean_pm2_5, 'PM10': mean_pm10}\n",
    "    all_data[year] = df.set_index('County').to_dict('index')  # Store data per county for bars\n",
    "\n",
    "# Set up the figure\n",
    "fig, ax1 = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Plotting yearly averages as lines\n",
    "years = list(yearly_averages.keys())\n",
    "pm2_5_averages = [yearly_averages[year]['PM2.5'] for year in years]\n",
    "pm10_averages = [yearly_averages[year]['PM10'] for year in years]\n",
    "\n",
    "# X positions for the plot\n",
    "x_positions = np.arange(len(years))\n",
    "\n",
    "# Line plots\n",
    "ax1.plot(x_positions, pm2_5_averages, marker='o', label='Average PM2.5', linestyle='-', color='blue')\n",
    "ax1.plot(x_positions, pm10_averages, marker='x', label='Average PM10', linestyle='--', color='red')\n",
    "\n",
    "# Labels and title for the line graph\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Average PM Concentration')\n",
    "ax1.set_title('Yearly Combined Average PM2.5 and PM10 Concentrations and Per County Breakdown')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# Adding a secondary axis for bar plots\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Width of each bar group\n",
    "bar_width = 0.1\n",
    "\n",
    "# Plotting bars for each county per year\n",
    "for i, year in enumerate(years):\n",
    "    counties = list(all_data[year].keys())\n",
    "    for j, county in enumerate(counties):\n",
    "        pm2_5 = all_data[year][county]['PM2.5']\n",
    "        pm10 = all_data[year][county]['PM10']\n",
    "        ax2.bar(i - bar_width/2 + j*bar_width, pm2_5, width=bar_width, label=f'PM2.5 {county}' if i == 0 else \"\", color='skyblue')\n",
    "        ax2.bar(i + bar_width/2 + j*bar_width, pm10, width=bar_width, label=f'PM10 {county}' if i == 0 else \"\", color='lightcoral')\n",
    "\n",
    "# Labels for the bars\n",
    "ax2.set_ylabel('County PM Concentration')\n",
    "\n",
    "# Adding bar legend to the right side\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "if handles:\n",
    "    ax2.legend(handles[:len(counties)*2], labels[:len(counties)*2], loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371567ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "years = [2020, 2021, 2022, 2023]\n",
    "data = {}\n",
    "\n",
    "# Load data from each file\n",
    "for year in years:\n",
    "    df = pd.read_csv(f'pm_concentrations{year}.csv')\n",
    "    data[year] = df.set_index('County').to_dict('index')\n",
    "\n",
    "# Computing yearly averages for line graphs\n",
    "yearly_avg_pm25 = [np.mean([data[year][county]['PM2.5'] for county in data[year]]) for year in years]\n",
    "yearly_avg_pm10 = [np.mean([data[year][county]['PM10'] for county in data[year]]) for year in years]\n",
    "\n",
    "# Setting up the figure and axes\n",
    "fig, ax1 = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Plot the line graph for combined averages\n",
    "x_positions = np.arange(len(years))\n",
    "ax1.plot(x_positions, yearly_avg_pm25, marker='o', label='Average PM2.5', color='blue', linestyle='-')\n",
    "ax1.plot(x_positions, yearly_avg_pm10, marker='x', label='Average PM10', color='red', linestyle='--')\n",
    "\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Average PM Concentration')\n",
    "ax1.set_title('Yearly Average PM Concentrations with Detailed County Breakdown')\n",
    "ax1.set_xticks(x_positions)\n",
    "ax1.set_xticklabels(years)\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# Adding a secondary axis for the bar charts\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.1\n",
    "\n",
    "# Plotting bars for each county per year\n",
    "for i, year in enumerate(years):\n",
    "    counties = list(data[year].keys())\n",
    "    offsets = np.linspace(-bar_width * len(counties) / 2, bar_width * len(counties) / 2, len(counties))\n",
    "    for j, county in enumerate(counties):\n",
    "        pm2_5 = data[year][county]['PM2.5']\n",
    "        pm10 = data[year][county]['PM10']\n",
    "        # Single bar per year with vertical partitions for counties\n",
    "        ax2.bar(x_positions[i] + offsets[j], pm2_5, bar_width, label=f'PM2.5 {county}' if i == 0 and j == 0 else \"\", color='skyblue')\n",
    "        ax2.bar(x_positions[i] + offsets[j], pm10, bar_width, bottom=pm2_5, label=f'PM10 {county}' if i == 0 and j == 0 else \"\", color='lightcoral')\n",
    "\n",
    "ax2.set_ylabel('County PM Concentration')\n",
    "\n",
    "# Adjust legend for clarity\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "if handles:\n",
    "    ax2.legend(handles[0:2], labels[0:2], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f9879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67e7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
